{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "eb615d35",
=======
   "id": "5586f5c5",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "5586f5c5",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "# Data Collection and Preparation\n",
    "\n",
    "The following workbook collects all data required for the analysis. This includes: \n",
    "\n",
    " * Economic data: GDP per capita growth rates and inflation rates\n",
    " * Coronavirus data: daily case numbers, total cases, deaths\n",
    " * Fear and greed index: related to Crypto assets and stocks\n",
    " * Asset price data: Bitcoin, Ethereum, S & P 500 and overall Cryptocurrency market capitilisation figure\n",
    "\n",
    "---\n",
    "\n",
    "### Import the modules required for the analysis\n",
    "\n",
    "The data collection process involves the use of a number of key Python modules, specifically pandas."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
<<<<<<< HEAD
   "id": "0a6ff387",
=======
   "id": "d8775203",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": 22,
   "id": "d8775203",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules required for the analysis\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "from pathlib import Path"
=======
=======
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
    "from pathlib import Path\n",
    "import bs4 as bs\n",
    "import requests\n",
    "import warnings\n",
    "import yfinance as yf\n",
<<<<<<< HEAD
    "from visual import create_forecast"
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
    "import time\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")"
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "a375ecd0",
=======
   "id": "0879fa13",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "0879fa13",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "### Coronavirus Data\n",
    "\n",
    "This section of the data collection process collects time series data related to COVID-19. The objective of collecting this data is to prepare the dataset for multiple visualisations (such as geographic representation and time-series comparison against other indicators). "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
<<<<<<< HEAD
   "id": "69978eed",
=======
   "id": "ff0415c3",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": 7,
   "id": "ff0415c3",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso_code                                    object\n",
      "continent                                   object\n",
      "location                                    object\n",
      "date                                        object\n",
      "total_cases                                float64\n",
      "                                            ...   \n",
      "human_development_index                    float64\n",
      "excess_mortality_cumulative_absolute       float64\n",
      "excess_mortality_cumulative                float64\n",
      "excess_mortality                           float64\n",
      "excess_mortality_cumulative_per_million    float64\n",
      "Length: 67, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
       "1      AFG      Asia  Afghanistan  2020-02-25          5.0        0.0   \n",
       "2      AFG      Asia  Afghanistan  2020-02-26          5.0        0.0   \n",
       "3      AFG      Asia  Afghanistan  2020-02-27          5.0        0.0   \n",
       "4      AFG      Asia  Afghanistan  2020-02-28          5.0        0.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "1                 NaN           NaN         NaN                  NaN  ...   \n",
       "2                 NaN           NaN         NaN                  NaN  ...   \n",
       "3                 NaN           NaN         NaN                  NaN  ...   \n",
       "4                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                  37.746   \n",
       "1             NaN           NaN                  37.746   \n",
       "2             NaN           NaN                  37.746   \n",
       "3             NaN           NaN                  37.746   \n",
       "4             NaN           NaN                  37.746   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                         0.5            64.83                    0.511   \n",
       "1                         0.5            64.83                    0.511   \n",
       "2                         0.5            64.83                    0.511   \n",
       "3                         0.5            64.83                    0.511   \n",
       "4                         0.5            64.83                    0.511   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the URL to the raw github content\n",
    "url = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv'\n",
    "geo_url = 'https://raw.githubusercontent.com/albertyw/avenews/master/old/data/average-latitude-longitude-countries.csv'\n",
    "\n",
    "# Set path for writing CSV files to data\n",
    "write_path = \"./Data/\"\n",
    "\n",
    "# Read the covid data into a dataframe\n",
    "covid = pd.read_csv(url)\n",
    "\n",
    "# Read the geographic data into a dataframe\n",
    "geo_data = pd.read_csv(geo_url)\n",
    "\n",
    "# Print datatypes\n",
    "print(covid.dtypes)\n",
    "\n",
    "# Display data\n",
    "covid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "2a6a03a8",
=======
   "id": "cabad235",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "cabad235",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "Convert the date column to a datetime format using pandas' *to_datetime* function.\n",
    "\n",
    "Once completed, the code then filters for the time period that is being utilised for this report. For the purposes of analysis and data availability, the time period being used is from **1st March 2020 to 31st December 2021**. The data collected is being constantly updated and therefore needs to be filtered to capture the correct dates."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
<<<<<<< HEAD
   "id": "c99e16d8",
=======
   "id": "5c00e652",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": 8,
   "id": "5c00e652",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "covid['date'] = pd.to_datetime(covid['date'], infer_datetime_format = True)\n",
    "\n",
    "# Filter 'date' based on assessment period specified above\n",
    "covid = covid[(covid['date'] >= '2020-01-01') & (covid['date'] <= '2021-12-31')]"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "5fdef2cf",
=======
   "id": "17cd543a",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "17cd543a",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "The time series data is now prepared and available to use. Now grouped data is required per country for both 2020 and 2021."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
<<<<<<< HEAD
   "id": "34cd547a",
=======
   "id": "4c6e4cfd",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": 9,
   "id": "4c6e4cfd",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant columns, group by location and year and sum both total cases and year\n",
    "covid_grouped = covid.iloc[:,[2,3,5,8]].groupby(['location', covid.date.dt.year]).sum().reset_index().\\\n",
    "                                        rename(columns = {'new_cases' : 'Cases',\n",
    "                                                          'new_deaths' : 'Deaths',\n",
    "                                                          'location' : 'Country'})"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "93b1d17e",
=======
   "id": "862c243e",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "862c243e",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "The following code merges the *covid_grouped* dataframe with the *geo_data* dataframe to produce a combined dataframe with Covid-19 data and locational data."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
<<<<<<< HEAD
   "id": "b27251aa",
=======
   "id": "f63f0537",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": 10,
   "id": "f63f0537",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>date</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>ISO 3166 Country Code</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020</td>\n",
       "      <td>52330.0</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2021</td>\n",
       "      <td>105754.0</td>\n",
       "      <td>5167.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2020</td>\n",
       "      <td>58316.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2021</td>\n",
       "      <td>151908.0</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020</td>\n",
       "      <td>99610.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>2021</td>\n",
       "      <td>8027.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>YE</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2020</td>\n",
       "      <td>20725.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>ZM</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2021</td>\n",
       "      <td>233549.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>ZM</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020</td>\n",
       "      <td>13867.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>ZW</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021</td>\n",
       "      <td>199391.0</td>\n",
       "      <td>4641.0</td>\n",
       "      <td>ZW</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  date     Cases  Deaths ISO 3166 Country Code  Latitude  \\\n",
       "0    Afghanistan  2020   52330.0  2189.0                    AF      33.0   \n",
       "1    Afghanistan  2021  105754.0  5167.0                    AF      33.0   \n",
       "2        Albania  2020   58316.0  1181.0                    AL      41.0   \n",
       "3        Albania  2021  151908.0  2036.0                    AL      41.0   \n",
       "4        Algeria  2020   99610.0  2756.0                    DZ      28.0   \n",
       "..           ...   ...       ...     ...                   ...       ...   \n",
       "378        Yemen  2021    8027.0  1374.0                    YE      15.0   \n",
       "379       Zambia  2020   20725.0   388.0                    ZM     -15.0   \n",
       "380       Zambia  2021  233549.0  3346.0                    ZM     -15.0   \n",
       "381     Zimbabwe  2020   13867.0   363.0                    ZW     -20.0   \n",
       "382     Zimbabwe  2021  199391.0  4641.0                    ZW     -20.0   \n",
       "\n",
       "     Longitude  \n",
       "0         65.0  \n",
       "1         65.0  \n",
       "2         20.0  \n",
       "3         20.0  \n",
       "4          3.0  \n",
       "..         ...  \n",
       "378       48.0  \n",
       "379       30.0  \n",
       "380       30.0  \n",
       "381       30.0  \n",
       "382       30.0  \n",
       "\n",
       "[383 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join the locational data from geo_data with the covid_grouped dataframe\n",
    "covid_grouped = pd.merge(covid_grouped, geo_data, on = 'Country', how = 'inner')\n",
    "\n",
    "# Write the Covid-19 data to CSV format\n",
    "covid_grouped.to_csv(write_path + \"covid_yoy_data.csv\", index = False)\n",
    "\n",
    "# Display joined results\n",
    "covid_grouped"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "d47aaa7f",
=======
   "id": "273c3f26",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "273c3f26",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "### Economic data\n",
    "\n",
    "There are two primary economic indicators that will be used to answer a number of questions relating to this analysis. These are Gross Domestic Product (GDP) per capita (per capita translates to *'per person'*) and inflation (the increase in the price of goods and services)."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
<<<<<<< HEAD
   "id": "3939772f",
=======
   "id": "3c0debe4",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": 11,
   "id": "3c0debe4",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/real_gdp_growth.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20904/2839000100.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read real GDP growth data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreal_gdp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'real_gdp_growth.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Read inflation rate data from the worldbank API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minflation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'inflation_annual.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/real_gdp_growth.csv'"
     ]
    }
   ],
   "source": [
    "# Read real GDP growth data \n",
<<<<<<< HEAD
<<<<<<< HEAD
    "real_gdp = pd.read_csv('real_gdp_growth.csv')\n",
    "\n",
    "# Read inflation rate data from the worldbank API\n",
    "inflation = pd.read_csv('inflation_annual.csv')"
=======
=======
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
    "real_gdp = pd.read_csv(write_path + 'real_gdp_growth.csv')\n",
    "\n",
    "# Read inflation rate data from the worldbank API\n",
    "inflation = pd.read_csv(write_path + 'inflation_annual.csv')"
<<<<<<< HEAD
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "99d40faa",
=======
   "id": "a83a363a",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "a83a363a",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "The data is not presented in panel data format and thus should be structured accordingly. The following piece of code will prepare the data to be presented in a more appropriate format."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
<<<<<<< HEAD
   "id": "97365346",
=======
   "id": "3fbd22f0",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": null,
   "id": "3fbd22f0",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack data, reset index and rename columns\n",
    "real_gdp = real_gdp.set_index(['Country','Country Code', 'Indicator Name', 'Indicator Code']).\\\n",
    "                    stack().reset_index().rename(columns = {'level_4' : 'Year', \n",
    "                                                            0 : 'GDP per capita growth (annual %)'})\n",
    "\n",
    "# Select only relevant columns within the real_gdp dataframe\n",
    "real_gdp = real_gdp.iloc[:,[0,1,4,5]]\n",
    "\n",
    "# Apply the above logic inflation data\n",
    "inflation = inflation.set_index(['Country','Country Code', 'Indicator Name', 'Indicator Code']).\\\n",
    "                      stack().reset_index().rename(columns = {'level_4' : 'Year', \n",
    "                                                              0 : 'Inflation Rate'})\n",
    "\n",
    "# Select only relevant columns within the real_gdp dataframe\n",
    "inflation = inflation.iloc[:,[0,1,4,5]]"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "e2d26475",
=======
   "id": "26d73376",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "26d73376",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "Convert year column to datetime format."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
<<<<<<< HEAD
   "id": "1d77a242",
=======
   "id": "baf5f73f",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": null,
   "id": "baf5f73f",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dataframes\n",
    "economic_data = [real_gdp, inflation]\n",
    "\n",
    "# Initiate for loop\n",
    "for eco in economic_data:\n",
    "    \n",
    "    # Convert to datetime\n",
    "    eco['Year'] = pd.to_datetime(eco['Year'], infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "4e7793f9",
=======
   "id": "f5eb95cc",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "f5eb95cc",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "Join the dataframes."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
<<<<<<< HEAD
   "id": "7b5cc1fa",
=======
   "id": "9024fd29",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": null,
   "id": "9024fd29",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "eco_data = pd.merge(real_gdp, inflation, on = ['Country','Year','Country Code'] , how = 'inner')\n",
    "\n",
    "# Take the average inflation rate and GDP per capita growth rate for 2019 and 2020 only (to join with Covid-19 data)\n",
    "eco_avg = eco_data[eco_data['Year'] >= '2019-01-01'].groupby(['Country','Country Code',eco_data.Year.dt.year]).\\\n",
    "                                                     mean().rename(columns = {\n",
    "                                        'GDP per capita growth (annual %)' : 'Average GDP Per Capita Growth Rate',\n",
    "                                        'Inflation Rate' : 'Average Inflation Rate'}).reset_index()\n",
    "\n",
    "# Display results\n",
    "eco_avg"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "7929f8ee",
=======
   "id": "9fc45559",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "id": "9fc45559",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Combined Economic and Covid Data\n",
    "\n",
    "The following code combines both Coronavirus data prepared earlier in this workbook with the economic data prepared above. Data is joined based on country name. The following approach has been undertaken to deal with data quality issues: \n",
    "\n",
    " * Nations with a year of data missing will be excluded for completeness\n",
    "\n",
    "There are also a number of limitations to mention. These include:\n",
    "\n",
    " * Not all data is available for GDP per capita figures, meaning there will be exclusions in the dataset\n",
    " * Using country name as a joining key has proven somewhat effective, but may differ amongst datasets\n",
    " \n",
    "The following code combines the abovementioned dataframes."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
<<<<<<< HEAD
   "id": "00781e49",
=======
   "id": "d2db4758",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
   "execution_count": null,
   "id": "d2db4758",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes using country as the key\n",
    "eco_covid = pd.merge(eco_avg, \n",
    "                     covid_grouped, \n",
    "                     how = 'left', \n",
    "                     left_on = ['Country','Year'], \n",
    "                     right_on = ['Country','date'])\n",
    "\n",
    "# Count number of country occurrances to exclude from dataset (if not containing both 2019 and 2020 data)\n",
    "count_country = eco_covid.groupby('Country').size().reset_index(name = 'Count')\n",
    "\n",
    "# Join count to eco_covid dataframe\n",
    "eco_covid = pd.merge(eco_covid, count_country, on = 'Country', how = 'inner')\n",
    "\n",
    "# Remove any countries with missing 2019 or 2020 data\n",
    "eco_covid = eco_covid[eco_covid['Count'] > 1].drop(columns = 'Count')\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# Fill in NaN 2019 data with identical latitude and longitude data\n",
=======
    "# Fill in NaN 2019 data with identical latitude and longitude data for a more complete dataset\n",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
    "# Fill in NaN 2019 data with identical latitude and longitude data for a more complete dataset\n",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
    "eco_covid[['Latitude','Longitude']] = eco_covid.groupby('Country')[['Latitude','Longitude']].bfill()\n",
    "\n",
    "# Remove null values with missing data\n",
    "eco_covid = eco_covid[eco_covid['Latitude'].notna()]\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# Select only relevant columns\n",
    "eco_covid = eco_covid.iloc[:,[0,2,3,4,6,7,9,10]]"
=======
=======
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
    "# Assess economic impact of GDP per capita and inflation for each country\n",
    "eco_covid = eco_covid.iloc[:,[0,3,4,9,10]].set_index(['Country','Latitude','Longitude'])\n",
    "\n",
    "# Calculate difference\n",
    "eco_covid = eco_covid.groupby(eco_covid.index).diff().dropna(how = 'any').rename(columns = {\n",
    "                                        'Average GDP Per Capita Growth Rate' : 'Change in GDP (Year on Year)',\n",
    "                                        'Average Inflation Rate' : 'Change in Inflation Rate (Year on Year)'}).reset_index()\n",
    "\n",
    "# Identify GDP per capita impact (whether positive or negative): to be used in Mapbox\n",
    "eco_covid['Impact'] = eco_covid['Change in GDP (Year on Year)'].apply(lambda x : 'Negative' if x < 0 else 'Positive')\n",
    "\n",
    "# Convert GDP change to positive (to ensure mapbox 'size' argument is satisfied (does not accept negative float))\n",
    "eco_covid['Change in GDP (Year on Year)'] = eco_covid['Change in GDP (Year on Year)'].\\\n",
    "                                                apply(lambda x : (x * -1) if x < 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254640dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Cryptocurrency and stock index data\n",
    "\n",
    "The following code reads in the overall market capitalisation data for the entire cryptocurrency market, as well as Bitcoin and Ehtereum data.\n",
    "\n",
    "Other stock index data is also included in the analysis, specifically stock indices such as the Standard and Poor's 500 (S&P 500) index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd997ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path used where the data is located\n",
    "crypto_tmc_path = Path(\"./Data/crypto_tmc.csv\")\n",
    "\n",
    "# Read the CSV file\n",
    "crypto_tmc_data = pd.read_csv(crypto_tmc_path, \n",
    "                              index_col = \"date\", \n",
    "                              infer_datetime_format = True, \n",
    "                              parse_dates = True)\n",
    "\n",
    "# Reset the index\n",
    "crypto_tmc_data.reset_index(inplace = True)\n",
    "\n",
    "# Generate sample data\n",
    "crypto_tmc_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3de04",
   "metadata": {},
   "source": [
    "For overall market capitilsation figures, only the close figure and index (currently date) are relevant. The following code selects only the close column , resets the index column to allow for joins to other datasets, such as the fear and greed index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant columns\n",
    "crypto = crypto_tmc_data[['date','close']]\n",
    "\n",
    "# Generate sample data\n",
    "crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a960be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to CSV\n",
    "crypto.to_csv(write_path + 'cryptotmc_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd3f38",
   "metadata": {},
   "source": [
    "The following code reads in historical S&P 500, Bitcoin and Ethereum data into a dataframe format. Further analysis and cleaning is performed on the dataset to prepare for future joins in the report. Relevant columns are selected (close) as part of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3017124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain S&P500, Bitcoin and Ethereum data \n",
    "hist_data = yf.download(\"BTC-USD ETH-USD ^GSPC\", \n",
    "                        start = \"2018-01-01\", \n",
    "                        end = \"2021-12-31\")\n",
    "\n",
    "# Select only closing values\n",
    "hist_data = hist_data['Close']\n",
    "\n",
    "# Reset index\n",
    "hist_data = hist_data.reset_index()\n",
    "\n",
    "# Convert date column to datetime\n",
    "hist_data['Date'] = pd.to_datetime(hist_data['Date'], infer_datetime_format = True)\n",
    "\n",
    "# Display data\n",
    "hist_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a2f20",
   "metadata": {},
   "source": [
    "The following code scrapes the table of Wikipedia showing the companies that are included in the S&P 500 index. Once this data is captured, the code will assess top and bottom performers by completing API calls on each of the stocks. Top five and bottom five performers based off 12 months data will be assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab77003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the URL required\n",
    "sp_url = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "\n",
    "# Create soup object\n",
    "soup = bs.BeautifulSoup(sp_url.text)\n",
    "\n",
    "# Create empty list\n",
    "sp_tickers = []\n",
    "\n",
    "# Identify the table with stored tickers\n",
    "table = soup.find('table', {'class' : 'wikitable sortable'})\n",
    "\n",
    "# Obtain rows of tickers\n",
    "rows = table.findAll('tr')[1:]\n",
    "\n",
    "# Initiate for loop\n",
    "for row in rows:\n",
    "    \n",
    "    # Obtain ticker symbol in text format\n",
    "    ticker = row.findAll('td')[0].text\n",
    "    \n",
    "    # Append list with ticker name\n",
    "    sp_tickers.append(ticker[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0b420",
   "metadata": {},
   "source": [
    "The following piece of code reads in all companies that are included in the S&P 500 index and produces a dataframe. The YF API requires tickers to be separated by whitespace and does not accept lists. Therefore the approach was taken to join each of the list items into a single string and assign the string to a variable that the YF API accepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of tickers to string value for YF API to read\n",
    "ticker_string = ' '.join([str(ticker) for ticker in sp_tickers])\n",
    "\n",
    "# Obtain S&P500 data\n",
    "sp_all_data = yf.download(ticker_string, start = \"2020-02-01\", end = \"2021-12-31\")\n",
    "\n",
    "# Select only closing values\n",
    "sp_all_data = sp_all_data['Close']\n",
    "\n",
    "# Display data\n",
    "sp_all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c0153",
   "metadata": {},
   "source": [
    "The following code drops any NA values located in the dataset and calculates the return from March 2020 to December 2020 (key Covid-19 period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all NaN values from the data\n",
    "sp_all_data.dropna(how = 'all', inplace = True)\n",
    "\n",
    "# Select first and last row of dataframe pandas\n",
    "sp_all_data = sp_all_data.iloc[[0,-1]]\n",
    "\n",
    "# Create a new dataframe to capture the movement in share price from the start of the pandemic to end of 2020\n",
    "sp_movement = sp_all_data.pct_change()\n",
    "\n",
    "# Drop NA values\n",
    "sp_movement.dropna(how = 'all', inplace = True)\n",
    "\n",
    "# Present data in stacked format\n",
    "sp_movement = sp_movement.stack().reset_index().rename(columns = {'level_1' : 'Ticker',\n",
    "                                                                  0 : 'Percentage Change (%)'}).drop(columns = 'Date')\n",
    "\n",
    "# Multiple percentage change by 100\n",
    "sp_movement['Percentage Change (%)'] = sp_movement['Percentage Change (%)'] * 100\n",
    "\n",
    "# Display results\n",
    "sp_movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d80778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the most impacted stocks over the 2020 period\n",
    "poorest_performers = sp_movement.nsmallest(10,\n",
    "                                           'Percentage Change (%)',\n",
    "                                           keep = 'all')\n",
    "\n",
    "# Add in performance rating of bottom and top 10 for visualisations in main script\n",
    "poorest_performers['Performance'] = 'Bottom 10'\n",
    "\n",
    "# Select the best performing stocks over the 2020 period\n",
    "best_performers = sp_movement.nlargest(10,\n",
    "                                       'Percentage Change (%)',\n",
    "                                       keep = 'all')\n",
    "\n",
    "# Add in performance rating of bottom and top 10 for visualisations in main script\n",
    "best_performers['Performance'] = 'Top 10'\n",
    "\n",
    "# Regroup the data for a complete dataset\n",
    "performance_data = pd.concat([best_performers, \n",
    "                              poorest_performers])\n",
    "\n",
    "# Write to CSV\n",
    "performance_data.to_csv(write_path + \"PERFORMANCE_DATA.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8cac32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Fear and Greed Index\n",
    "\n",
    "The following code reads in the fear and greed index data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV file\n",
    "fear_greed = pd.read_csv(write_path + \"fear_greed_crypto.csv\")\n",
    "\n",
    "# Rename columns\n",
    "fear_greed.rename(columns = {'date' : 'Date',\n",
    "                             'fng_value' : 'Fear and Greed Value',\n",
    "                             'fng_classification' : 'Fear and Greed Classification'}, inplace = True)\n",
    "\n",
    "# Display results\n",
    "fear_greed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709b92d",
   "metadata": {},
   "source": [
    "Convert the date column to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date format to datetime format using Pandas\n",
    "fear_greed['Date'] = pd.to_datetime(fear_greed['Date'], infer_datetime_format = True)\n",
    "\n",
    "# Assess data types\n",
    "fear_greed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9538d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Bitcoin and Ethereum data onto the fear and greed index to produce new dataset\n",
    "fg_crypto = pd.merge(fear_greed, hist_data, on = 'Date', how = 'inner')\n",
    "\n",
    "# Rename columns for dataset\n",
    "fg_crypto = fg_crypto.rename(columns = {'BTC-USD' : 'Bitcoin',\n",
    "                                        'ETH-USD' : 'Ethereum',\n",
    "                                        '^GSPC' : 'S&P 500'}).sort_values('Date', ascending = True)\n",
    "\n",
    "# Apply moving average for feed and great index to smooth out volatility\n",
    "fg_crypto['Moving Avg FG Index'] = fg_crypto['Fear and Greed Value'].rolling(window = 30).mean()\n",
    "\n",
    "\n",
    "# Merge market cap crypto data with fg_crypto dataframe\n",
    "fg_crypto = pd.merge(fg_crypto, crypto, left_on = 'Date', right_on = 'date', how = 'inner')\n",
    "\n",
    "# Display results\n",
<<<<<<< HEAD
    "fg_crypto"
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "47e28291",
=======
   "id": "4ab3cbd6",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
    "fg_crypto = fg_crypto.drop(columns = ['date']).rename(columns = {\n",
    "    'close' : 'Crypto Market Capitilisation'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad78ad",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "fg_crypto.to_csv(write_path + 'fear_greed_crypto_clean.csv', index = False)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "id": "60f17253",
=======
   "execution_count": 22,
   "id": "f0c2005b",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "After the data preparation process, there are 124.0 countries with available data.\n",
      "Code executed without error at 2022-01-05 22:58:15.125570\n"
=======
      "After the data preparation process, there are 62.0 countries with available data.\n",
      "Code executed without error at 2022-01-09 22:13:04.988204\n"
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
<<<<<<< HEAD
       "      <th>Year</th>\n",
       "      <th>Average GDP Per Capita Growth Rate</th>\n",
       "      <th>Average Inflation Rate</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
=======
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Change in GDP (Year on Year)</th>\n",
       "      <th>Change in Inflation Rate (Year on Year)</th>\n",
       "      <th>Impact</th>\n",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>5</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.549359</td>\n",
       "      <td>1.411091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2020</td>\n",
       "      <td>-3.398708</td>\n",
       "      <td>1.620887</td>\n",
       "      <td>58316.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2019</td>\n",
       "      <td>-0.934556</td>\n",
       "      <td>1.951768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020</td>\n",
       "      <td>-6.826964</td>\n",
       "      <td>2.415131</td>\n",
       "      <td>99610.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>2019</td>\n",
       "      <td>7.382197</td>\n",
       "      <td>1.443447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
=======
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>41.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>5.948067</td>\n",
       "      <td>0.209796</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.892408</td>\n",
       "      <td>0.463363</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>40.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>14.954258</td>\n",
       "      <td>-0.232011</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>-27.00</td>\n",
       "      <td>133.00</td>\n",
       "      <td>1.825701</td>\n",
       "      <td>-0.763862</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>47.33</td>\n",
       "      <td>13.33</td>\n",
       "      <td>8.165388</td>\n",
       "      <td>-0.148985</td>\n",
       "      <td>Negative</td>\n",
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
<<<<<<< HEAD
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>2020</td>\n",
       "      <td>-6.183824</td>\n",
       "      <td>9.756406</td>\n",
       "      <td>19119.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.001037</td>\n",
       "      <td>2.795824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.979231</td>\n",
       "      <td>3.220934</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2019</td>\n",
       "      <td>-1.451364</td>\n",
       "      <td>9.150316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2020</td>\n",
       "      <td>-5.550283</td>\n",
       "      <td>15.732585</td>\n",
       "      <td>20725.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Year  Average GDP Per Capita Growth Rate  \\\n",
       "5    Albania  2019                            2.549359   \n",
       "6    Albania  2020                           -3.398708   \n",
       "7    Algeria  2019                           -0.934556   \n",
       "8    Algeria  2020                           -6.826964   \n",
       "13   Armenia  2019                            7.382197   \n",
       "..       ...   ...                                 ...   \n",
       "391  Uruguay  2020                           -6.183824   \n",
       "393  Vietnam  2019                            6.001037   \n",
       "394  Vietnam  2020                            1.979231   \n",
       "399   Zambia  2019                           -1.451364   \n",
       "400   Zambia  2020                           -5.550283   \n",
       "\n",
       "     Average Inflation Rate    Cases  Deaths  Latitude  Longitude  \n",
       "5                  1.411091      NaN     NaN      41.0       20.0  \n",
       "6                  1.620887  58316.0  1181.0      41.0       20.0  \n",
       "7                  1.951768      NaN     NaN      28.0        3.0  \n",
       "8                  2.415131  99610.0  2756.0      28.0        3.0  \n",
       "13                 1.443447      NaN     NaN      40.0       45.0  \n",
       "..                      ...      ...     ...       ...        ...  \n",
       "391                9.756406  19119.0   181.0     -33.0      -56.0  \n",
       "393                2.795824      NaN     NaN      16.0      106.0  \n",
       "394                3.220934   1465.0    35.0      16.0      106.0  \n",
       "399                9.150316      NaN     NaN     -15.0       30.0  \n",
       "400               15.732585  20725.0   388.0     -15.0       30.0  \n",
       "\n",
       "[248 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>54.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>11.302967</td>\n",
       "      <td>-0.748618</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>United States</td>\n",
       "      <td>38.00</td>\n",
       "      <td>-97.00</td>\n",
       "      <td>5.676563</td>\n",
       "      <td>-0.578626</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>-33.00</td>\n",
       "      <td>-56.00</td>\n",
       "      <td>6.173625</td>\n",
       "      <td>1.874418</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>16.00</td>\n",
       "      <td>106.00</td>\n",
       "      <td>4.021806</td>\n",
       "      <td>0.425111</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>4.098919</td>\n",
       "      <td>6.582269</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Country  Latitude  Longitude  Change in GDP (Year on Year)  \\\n",
       "0           Albania     41.00      20.00                      5.948067   \n",
       "1           Algeria     28.00       3.00                      5.892408   \n",
       "2           Armenia     40.00      45.00                     14.954258   \n",
       "3         Australia    -27.00     133.00                      1.825701   \n",
       "4           Austria     47.33      13.33                      8.165388   \n",
       "..              ...       ...        ...                           ...   \n",
       "119  United Kingdom     54.00      -2.00                     11.302967   \n",
       "120   United States     38.00     -97.00                      5.676563   \n",
       "121         Uruguay    -33.00     -56.00                      6.173625   \n",
       "122         Vietnam     16.00     106.00                      4.021806   \n",
       "123          Zambia    -15.00      30.00                      4.098919   \n",
       "\n",
       "     Change in Inflation Rate (Year on Year)    Impact  \n",
       "0                                   0.209796  Negative  \n",
       "1                                   0.463363  Negative  \n",
       "2                                  -0.232011  Negative  \n",
       "3                                  -0.763862  Negative  \n",
       "4                                  -0.148985  Negative  \n",
       "..                                       ...       ...  \n",
       "119                                -0.748618  Negative  \n",
       "120                                -0.578626  Negative  \n",
       "121                                 1.874418  Negative  \n",
       "122                                 0.425111  Negative  \n",
       "123                                 6.582269  Negative  \n",
       "\n",
       "[124 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print sample size and code completion\n",
    "print(f\"After the data preparation process, there are {(eco_covid['Country'].count())/2} countries with available data.\")\n",
    "print(f\"Code executed without error at {dt.datetime.now()}\")\n",
    "\n",
<<<<<<< HEAD
    "# Display results\n",
    "eco_covid"
=======
    "# Print to CSV\n",
    "eco_covid.to_csv(write_path + \"eco_covid.csv\", index = False)\n",
=======
   "cell_type": "markdown",
   "id": "eeb696f0",
   "metadata": {},
   "source": [
    "## Whale Wallet Activity BTC\n",
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
    "\n",
    "The following code reads the csv file obtained a single wallet containing the most amount of Bitcoin through a block explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f53d4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_whale = Path(\"./Data/btc_whale.csv\")\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "btc_whale_data = pd.read_csv(btc_whale, \n",
    "                             index_col = \"Date\",\n",
    "                              infer_datetime_format = True, \n",
    "                              parse_dates = True)\n",
    "\n",
    "btc_whale_data.reset_index(inplace = True)\n",
    "\n",
    "#Selecting relevant columns\n",
    "btc_whale_data =  btc_whale_data[['Date', 'Amount', 'Balance (USD)']]\n",
    "\n",
    "#Data cleaning splitting balance of Bitoin in wallet in USD from the BTC price at the time of purchase\n",
    "btc_whale_data['balance_new'] = btc_whale_data['Balance (USD)'].str.split('@').str[0]\n",
    "\n",
    "#Data cleaning splitting the amount of BTC purchased from BTC price and USD value\n",
    "btc_whale_data['amount_new'] = btc_whale_data['Amount'].str.split('B').str[0]\n",
    "btc_whale_data['amount_new2'] = btc_whale_data['Amount'].str.split(' ').str[1]\n",
    "\n",
    "#Removing \"+\" from amount of BTC purchased and changing datatype as float\n",
    "btc_whale_data['amount_new'] = btc_whale_data['amount_new'].str.replace('[+,]','').astype(float)\n",
    "\n",
    "#Dropping unnecessary columns\n",
    "btc_whale_data = btc_whale_data.drop(columns=['Amount', 'Balance (USD)'])\n",
    "\n",
    "#Changing column names\n",
    "btc_whale_data['balance_new'] = btc_whale_data['balance_new'].str.replace(r'\\D+', '', regex=True)\n",
    "btc_whale_data['amount_new2'] = btc_whale_data['amount_new2'].str.replace(r'\\D+', '', regex=True)\n",
    "btc_whale_data = btc_whale_data.rename(columns = {'balance_new':'Wallet Balance',\n",
    "                                                  'amount_new':'BTC Buy/Sell (BTC)',\n",
    "                                                  'amount_new2':'BTC Buy/Sell (USD)'})\n",
    "\n",
    "btc_whale_data = btc_whale_data[['Date','Wallet Balance', 'BTC Buy/Sell (BTC)']]\n",
    "btc_whale_data['Date'] = btc_whale_data['Date'].dt.strftime(\"%Y-%m-%d\")\n",
    "btc_whale_data = btc_whale_data.groupby('Date').agg({'Wallet Balance' : 'sum',\n",
    "                                                     'BTC Buy/Sell (BTC)' : 'sum'}).reset_index()\n",
    "#Save to csv\n",
    "btc_whale_data.to_csv(write_path + 'final_data_whale_btc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3cbd6",
   "metadata": {},
   "source": [
    "### Final remarks\n",
    "\n",
    "With the removal of null values and countries with missing data, the dataset for assessing Covid-19 impacts is ready for use. The following code confirms the available data and the structure of the new dataframe that will be used in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2005b",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "gdp_data = pd.DataFrame(list(zip(country_data, current_gdp_list, previous_gdp_list)))\n",
    "gdp_data.columns = ['Country', '2021 GDP', '2020 GDP']\n",
    "gdp_data"
>>>>>>> a986ad26d397ef61e7702415206222998a11bd1b
=======
    "# Print sample size and code completion\n",
    "print(f\"After the data preparation process, there are {(eco_covid['Country'].count())/2} countries with available data.\")\n",
    "print(f\"Code executed without error at {dt.datetime.now()}\")\n",
    "\n",
    "# Print to CSV\n",
    "eco_covid.to_csv(write_path + \"eco_covid.csv\", index = False)\n",
    "\n",
    "# Display results\n",
    "eco_covid"
>>>>>>> 3d441a8aa247245e38878de7e59364e0f5729451
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
